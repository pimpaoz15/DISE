{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiI92gU7k3FI"
      },
      "source": [
        "# Spaceship Titanic\n",
        "\n",
        "\n",
        "**Dataset Description**\n",
        "In this competition your task is to predict whether a passenger was transported to an alternate dimension during the Spaceship Titanic's collision with the spacetime anomaly. To help you make these predictions, you're given a set of personal records recovered from the ship's damaged computer system.\n",
        "\n",
        "**File and Data Field Descriptions**\n",
        "\n",
        "train.csv - Personal records for about two-thirds (8700) of the passengers, to be used as training data.\n",
        "\n",
        "PassengerId - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n",
        "\n",
        "HomePlanet - The planet the passenger departed from, typically their planet of permanent residence.\n",
        "\n",
        "CryoSleep - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n",
        "\n",
        "Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n",
        "\n",
        "Destination - The planet the passenger will be debarking to.\n",
        "\n",
        "Age - The age of the passenger.\n",
        "\n",
        "VIP - Whether the passenger has paid for special VIP service during the voyage.\n",
        "RoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n",
        "\n",
        "Name - The first and last names of the passenger.\n",
        "\n",
        "Transported - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.\n",
        "\n",
        "test.csv - Personal records for the remaining one-third (~4300) of the passengers, to be used as test data. Your task is to predict the value of Transported for the passengers in this set.\n",
        "\n",
        "PassengerId - Id for each passenger in the test set.\n",
        "\n",
        "Transported - The target. For each passenger, predict either True or False.\n",
        "\n",
        " # **The lab consist in a competition to see which students gets a better result in the test set. You will need to explain with code comments or text which steps are you following.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kcp4DGoMk05A",
        "outputId": "e1414e43-6ba2-4fe9-8fed-1508775dc3cf"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "7IheEC7xSKbX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set pandas to display wider tables\n",
        "pd.set_option('display.width', 1000)\n",
        "pd.set_option('display.max_columns', 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "TJGMLyFmRqbd"
      },
      "outputs": [],
      "source": [
        "#SpaceTrain = pd.read_csv(\"/content/drive/MyDrive/DataIntesive/Data/train_Lab3.csv\")\n",
        "SpaceTrain = pd.read_csv(\"train_Lab3.csv\")\n",
        "\n",
        "#SpaceTest = pd.read_csv(\"/content/drive/MyDrive/DataIntesive/Data/test_Lab3.csv\")\n",
        "SpaceTest = pd.read_csv(\"test_Lab3.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6VOjJ3cHR_4X",
        "outputId": "563ee62c-02bc-4497-cf43-bfd362447980"
      },
      "outputs": [],
      "source": [
        "SpaceTrain.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VqtsTc8PSVHe",
        "outputId": "85ea9b22-0d9f-4db4-8c40-b7cf1bfec2fe"
      },
      "outputs": [],
      "source": [
        "SpaceTest.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exploring the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check the first few rows of both datasets\n",
        "print(\"Training Data:\")\n",
        "print(SpaceTrain.head())\n",
        "\n",
        "print(\"\\n\") # Add a line break\n",
        "\n",
        "print(\"Test Data:\")\n",
        "print(SpaceTest.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check dimensions of the datasets\n",
        "print(f\"Training data shape: {SpaceTrain.shape}\")\n",
        "\n",
        "print(f\"Test data shape: {SpaceTest.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values in both datasets\n",
        "print(\"Missing values in training data:\")\n",
        "print(SpaceTrain.isnull().sum())\n",
        "\n",
        "print(\"\\n\") # Add a line break\n",
        "\n",
        "print(\"Missing values in test data:\")\n",
        "print(SpaceTest.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check data types of each column in both datasets\n",
        "print(\"Training data types:\")\n",
        "print(SpaceTrain.info())\n",
        "\n",
        "print(\"\\n\") # Add a line break\n",
        "\n",
        "print(\"Test data types:\")\n",
        "print(SpaceTest.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic statistics for numerical features in both datasets\n",
        "print(\"Training data statistics:\")\n",
        "print(SpaceTrain.describe())\n",
        "\n",
        "print(\"Test data statistics:\")\n",
        "print(SpaceTest.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualizing the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plot the distribution of the target variable\n",
        "sns.countplot(x='Transported', data=SpaceTrain)\n",
        "plt.title('Distribution of Transported')\n",
        "plt.show()\n",
        "\n",
        "# Plot the distribution of HomePlanet\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.countplot(x='HomePlanet', data=SpaceTrain)\n",
        "plt.title('Distribution of HomePlanet')\n",
        "plt.show()\n",
        "\n",
        "# Plot the distribution of CryoSleep\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.countplot(x='CryoSleep', data=SpaceTrain)\n",
        "plt.title('Distribution of CryoSleep')\n",
        "plt.show()\n",
        "\n",
        "# Plot the distribution of VIP\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.countplot(x='VIP', data=SpaceTrain)\n",
        "plt.title('Distribution of VIP')\n",
        "plt.show()\n",
        "\n",
        "# Plot the distribution of Age\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(SpaceTrain['Age'].dropna(), kde=True)\n",
        "plt.title('Distribution of Age')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Handling Missing Values/Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill missing values for categorical columns with the mode\n",
        "SpaceTrain['HomePlanet'].fillna(SpaceTrain['HomePlanet'].mode()[0], inplace=True)\n",
        "SpaceTrain['Destination'].fillna(SpaceTrain['Destination'].mode()[0], inplace=True)\n",
        "SpaceTrain['CryoSleep'].fillna(SpaceTrain['CryoSleep'].mode()[0], inplace=True)\n",
        "SpaceTrain['VIP'].fillna(SpaceTrain['VIP'].mode()[0], inplace=True)\n",
        "\n",
        "# Fill missing values for numerical columns with the median\n",
        "SpaceTrain['Age'].fillna(SpaceTrain['Age'].median(), inplace=True)\n",
        "SpaceTrain['RoomService'].fillna(SpaceTrain['RoomService'].median(), inplace=True)\n",
        "SpaceTrain['FoodCourt'].fillna(SpaceTrain['FoodCourt'].median(), inplace=True)\n",
        "SpaceTrain['ShoppingMall'].fillna(SpaceTrain['ShoppingMall'].median(), inplace=True)\n",
        "SpaceTrain['Spa'].fillna(SpaceTrain['Spa'].median(), inplace=True)\n",
        "SpaceTrain['VRDeck'].fillna(SpaceTrain['VRDeck'].median(), inplace=True)\n",
        "\n",
        "# Do the same for the test data\n",
        "SpaceTest['HomePlanet'].fillna(SpaceTest['HomePlanet'].mode()[0], inplace=True)\n",
        "SpaceTest['Destination'].fillna(SpaceTest['Destination'].mode()[0], inplace=True)\n",
        "SpaceTest['CryoSleep'].fillna(SpaceTest['CryoSleep'].mode()[0], inplace=True)\n",
        "SpaceTest['VIP'].fillna(SpaceTest['VIP'].mode()[0], inplace=True)\n",
        "\n",
        "SpaceTest['Age'].fillna(SpaceTest['Age'].median(), inplace=True)\n",
        "SpaceTest['RoomService'].fillna(SpaceTest['RoomService'].median(), inplace=True)\n",
        "SpaceTest['FoodCourt'].fillna(SpaceTest['FoodCourt'].median(), inplace=True)\n",
        "SpaceTest['ShoppingMall'].fillna(SpaceTest['ShoppingMall'].median(), inplace=True)\n",
        "SpaceTest['Spa'].fillna(SpaceTest['Spa'].median(), inplace=True)\n",
        "SpaceTest['VRDeck'].fillna(SpaceTest['VRDeck'].median(), inplace=True)\n",
        "\n",
        "# Handle missing values in the Cabin column\n",
        "# Split the Cabin column into Deck, Num, and Side\n",
        "SpaceTrain[['Deck', 'Num', 'Side']] = SpaceTrain['Cabin'].str.split('/', expand=True)\n",
        "SpaceTest[['Deck', 'Num', 'Side']] = SpaceTest['Cabin'].str.split('/', expand=True)\n",
        "\n",
        "# Fill missing values for 'Deck' and 'Side' with mode, and 'Num' with median\n",
        "SpaceTrain['Deck'].fillna(SpaceTrain['Deck'].mode()[0], inplace=True)\n",
        "SpaceTrain['Num'].fillna(SpaceTrain['Num'].median(), inplace=True)\n",
        "SpaceTrain['Side'].fillna(SpaceTrain['Side'].mode()[0], inplace=True)\n",
        "\n",
        "SpaceTest['Deck'].fillna(SpaceTest['Deck'].mode()[0], inplace=True)\n",
        "SpaceTest['Num'].fillna(SpaceTest['Num'].median(), inplace=True)\n",
        "SpaceTest['Side'].fillna(SpaceTest['Side'].mode()[0], inplace=True)\n",
        "\n",
        "# Optionally, drop the Name column if not needed\n",
        "SpaceTrain.drop('Name', axis=1, inplace=True)\n",
        "SpaceTest.drop('Name', axis=1, inplace=True)\n",
        "\n",
        "# Optionally, drop the original Cabin column since it's split into Deck, Num, and Side\n",
        "SpaceTrain.drop('Cabin', axis=1, inplace=True)\n",
        "SpaceTest.drop('Cabin', axis=1, inplace=True)\n",
        "\n",
        "# Final check for missing values\n",
        "print(\"Remaining missing values in SpaceTrain after handling:\")\n",
        "print(SpaceTrain.isnull().sum())\n",
        "\n",
        "print(\"\\nRemaining missing values in SpaceTest after handling:\")\n",
        "print(SpaceTest.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the Cabin feature into Deck, Num, and Side\n",
        "SpaceTrain[['Deck', 'Num', 'Side']] = SpaceTrain['Cabin'].str.split('/', expand=True)\n",
        "SpaceTrain['Num'] = SpaceTrain['Num'].astype(float)  # Convert Num to numeric\n",
        "\n",
        "SpaceTest[['Deck', 'Num', 'Side']] = SpaceTest['Cabin'].str.split('/', expand=True)\n",
        "SpaceTest['Num'] = SpaceTest['Num'].astype(float)\n",
        "\n",
        "# Create group size from PassengerId\n",
        "SpaceTrain['Group'] = SpaceTrain['PassengerId'].apply(lambda x: x.split('_')[0])\n",
        "SpaceTrain['GroupSize'] = SpaceTrain.groupby('Group')['PassengerId'].transform('count')\n",
        "\n",
        "SpaceTest['Group'] = SpaceTest['PassengerId'].apply(lambda x: x.split('_')[0])\n",
        "SpaceTest['GroupSize'] = SpaceTest.groupby('Group')['PassengerId'].transform('count')\n",
        "\n",
        "# Create TotalSpending feature\n",
        "SpaceTrain['TotalSpending'] = SpaceTrain[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n",
        "SpaceTest['TotalSpending'] = SpaceTest[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Label Encoding Categorical Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# # Initialize the label encoder\n",
        "# le = LabelEncoder()\n",
        "\n",
        "# # Combine the training and test sets for fitting the encoder\n",
        "# combined_cryo_sleep = pd.concat([SpaceTrain['CryoSleep'], SpaceTest['CryoSleep']])\n",
        "# combined_vip = pd.concat([SpaceTrain['VIP'], SpaceTest['VIP']])\n",
        "# combined_home_planet = pd.concat([SpaceTrain['HomePlanet'], SpaceTest['HomePlanet']])\n",
        "# combined_destination = pd.concat([SpaceTrain['Destination'], SpaceTest['Destination']])\n",
        "# combined_deck = pd.concat([SpaceTrain['Deck'], SpaceTest['Deck']])\n",
        "# combined_side = pd.concat([SpaceTrain['Side'], SpaceTest['Side']])\n",
        "\n",
        "# # Fit on combined data, then transform training and test sets separately\n",
        "\n",
        "# # CryoSleep\n",
        "# le.fit(combined_cryo_sleep.astype(str))\n",
        "# SpaceTrain['CryoSleep'] = le.transform(SpaceTrain['CryoSleep'].astype(str))\n",
        "# SpaceTest['CryoSleep'] = le.transform(SpaceTest['CryoSleep'].astype(str))\n",
        "\n",
        "# # VIP\n",
        "# le.fit(combined_vip.astype(str))\n",
        "# SpaceTrain['VIP'] = le.transform(SpaceTrain['VIP'].astype(str))\n",
        "# SpaceTest['VIP'] = le.transform(SpaceTest['VIP'].astype(str))\n",
        "\n",
        "# # HomePlanet\n",
        "# le.fit(combined_home_planet.astype(str))\n",
        "# SpaceTrain['HomePlanet'] = le.transform(SpaceTrain['HomePlanet'].astype(str))\n",
        "# SpaceTest['HomePlanet'] = le.transform(SpaceTest['HomePlanet'].astype(str))\n",
        "\n",
        "# # Destination\n",
        "# le.fit(combined_destination.astype(str))\n",
        "# SpaceTrain['Destination'] = le.transform(SpaceTrain['Destination'].astype(str))\n",
        "# SpaceTest['Destination'] = le.transform(SpaceTest['Destination'].astype(str))\n",
        "\n",
        "# # Deck\n",
        "# le.fit(combined_deck.astype(str))\n",
        "# SpaceTrain['Deck'] = le.transform(SpaceTrain['Deck'].astype(str))\n",
        "# SpaceTest['Deck'] = le.transform(SpaceTest['Deck'].astype(str))\n",
        "\n",
        "# # Side\n",
        "# le.fit(combined_side.astype(str))\n",
        "# SpaceTrain['Side'] = le.transform(SpaceTrain['Side'].astype(str))\n",
        "# SpaceTest['Side'] = le.transform(SpaceTest['Side'].astype(str))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Split the data into features and target\n",
        "X = SpaceTrain.drop(['Transported', 'PassengerId', 'Name', 'Cabin', 'Group'], axis=1)  # Drop irrelevant columns\n",
        "y = SpaceTrain['Transported'].astype(int)  # Ensure the target is in binary format (0,1)\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Show dataset dimensions\n",
        "print(f\"Training samples: {X_train.shape[0]}, Test samples: {X_val.shape[0]}\")\n",
        "\n",
        "# Standardize the numerical features\n",
        "scaler = StandardScaler()\n",
        "numerical_columns = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'TotalSpending', 'Num']\n",
        "X_train[numerical_columns] = scaler.fit_transform(X_train[numerical_columns])\n",
        "X_val[numerical_columns] = scaler.transform(X_val[numerical_columns])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Create an imputer for numerical columns\n",
        "numerical_imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "# Impute the missing values in numerical columns\n",
        "X_train[numerical_columns] = numerical_imputer.fit_transform(X_train[numerical_columns])\n",
        "X_val[numerical_columns] = numerical_imputer.transform(X_val[numerical_columns])\n",
        "\n",
        "# Impute missing values in categorical columns (using the most frequent value)\n",
        "categorical_columns = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP', 'Deck', 'Side']\n",
        "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "X_train[categorical_columns] = categorical_imputer.fit_transform(X_train[categorical_columns])\n",
        "X_val[categorical_columns] = categorical_imputer.transform(X_val[categorical_columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "# HistGradientBoosting Classifier (this can handle missing values natively)\n",
        "hist_gb_clf = HistGradientBoostingClassifier(random_state=42)\n",
        "hist_gb_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_hist_gb = hist_gb_clf.predict(X_val)\n",
        "\n",
        "# Evaluate HistGradientBoosting\n",
        "print(\"HistGradientBoosting Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_val, y_pred_hist_gb):.4f}\")\n",
        "print(classification_report(y_val, y_pred_hist_gb))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Boosting Model/Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Boosting algorithms for the Spaceship Titanic dataset\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Reusing X_train, X_val, y_train, y_val from earlier\n",
        "\n",
        "# AdaBoost Classifier\n",
        "ada_clf = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
        "ada_clf.fit(X_train, y_train)\n",
        "y_pred_ada = ada_clf.predict(X_val)\n",
        "print(\"AdaBoost Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_val, y_pred_ada):.4f}\")\n",
        "print(classification_report(y_val, y_pred_ada))\n",
        "\n",
        "# Gradient Boosting Classifier\n",
        "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "gb_clf.fit(X_train, y_train)\n",
        "y_pred_gb = gb_clf.predict(X_val)\n",
        "print(\"Gradient Boosting Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_val, y_pred_gb):.4f}\")\n",
        "print(classification_report(y_val, y_pred_gb))\n",
        "\n",
        "# XGBoost Classifier\n",
        "xgb_clf = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42, eval_metric='logloss')\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb_clf.predict(X_val)\n",
        "print(\"XGBoost Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_val, y_pred_xgb):.4f}\")\n",
        "print(classification_report(y_val, y_pred_xgb))\n",
        "\n",
        "# CatBoost Classifier\n",
        "catboost_clf = CatBoostClassifier(iterations=100, learning_rate=0.1, depth=3, verbose=0, random_state=42)\n",
        "catboost_clf.fit(X_train, y_train)\n",
        "y_pred_catboost = catboost_clf.predict(X_val)\n",
        "print(\"CatBoost Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_val, y_pred_catboost):.4f}\")\n",
        "print(classification_report(y_val, y_pred_catboost))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.neighbors import KNeighborsClassifier\n",
        "# from sklearn.svm import SVC\n",
        "# import xgboost as xgb\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "# from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# # List of classifiers to evaluate\n",
        "# classifiers = {\n",
        "#     'Random Forest': RandomForestClassifier(random_state=42),\n",
        "#     'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
        "#     'XGBoost': xgb.XGBClassifier(random_state=42, eval_metric='logloss'),\n",
        "#     'Logistic Regression': LogisticRegression(random_state=42),\n",
        "#     'KNN': KNeighborsClassifier(),\n",
        "#     'SVM': SVC(random_state=42)\n",
        "# }\n",
        "\n",
        "# # Function to train and evaluate the models\n",
        "# def evaluate_classifiers(classifiers, X_train, y_train, X_val, y_val):\n",
        "#     for name, clf in classifiers.items():\n",
        "#         # Train the model\n",
        "#         clf.fit(X_train, y_train)\n",
        "        \n",
        "#         # Predict on the validation set\n",
        "#         y_pred = clf.predict(X_val)\n",
        "        \n",
        "#         # Evaluate the performance\n",
        "#         accuracy = accuracy_score(y_val, y_pred)\n",
        "#         print(f\"Classifier: {name}\")\n",
        "#         print(f\"Accuracy: {accuracy:.4f}\")\n",
        "#         print(classification_report(y_val, y_pred))\n",
        "#         print(\"\\n\")\n",
        "\n",
        "\n",
        "# # Call the evaluation function\n",
        "# evaluate_classifiers(classifiers, X_train, y_train, X_val, y_val)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# # Function to evaluate classifiers using cross-validation\n",
        "# def cross_validate_classifiers(classifiers, X_train, y_train, cv=5):\n",
        "#     for name, clf in classifiers.items():\n",
        "#         # Perform cross-validation\n",
        "#         cv_scores = cross_val_score(clf, X_train, y_train, cv=cv, scoring='accuracy')\n",
        "        \n",
        "#         # Print the cross-validation results\n",
        "#         print(f\"Classifier: {name}\")\n",
        "#         print(f\"Mean CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\\n\")\n",
        "\n",
        "# # Perform cross-validation\n",
        "# cross_validate_classifiers(classifiers, X_train, y_train)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
